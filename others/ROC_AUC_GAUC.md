

## 符号定义

TP、TN、FP、FN这些符号与混淆矩阵相关。T代表预测的结果与真实标签一致，F代表预测的结果与真实标签不同。P和N分别代表预测的标签是positive和negative。

## 为什么要使用ROC

既然已经这么多评价标准，为什么还要使用ROC和AUC呢？因为ROC曲线有个很好的特性：当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变。在实际的数据集中经常会出现类不平衡(class imbalance)现象，即负样本比正样本多很多(或者相反)，而且测试数据中的正负样本的分布也可能随着时间变化。我们可以尝试使用同一个模型，在样本标签分布改变的情况下进行预测并且重新绘制ROC，可以在实验中发现曲线变化不大。这样可以对每个模型进行稳定的评估。

## ROC

- 真阳性率(true positive rate，TPR)，又称敏感度(sensitivity，SEN)，计算公式为： $TPR = \dfrac{TP}{TP+FN}$， 形式上与召回率 ( Recall ) 相同。

- 假阳性率(false positive rate，FPR)，计算公式为： $FPR = \dfrac{FP}{FP+TN}$。

ROC (receiver operating characteristic) 曲线以假阳性率作为横轴，以真阳性率作为纵轴，图中的点**从右到左**代表模型判定P、N时的阈值从0到1改变时，假阳性率和真阳性率的变化情况。ROC图中左下角的点代表模型将样本全部判定为F，右上角的点代表模型将样本全部判定为P。

## AUC

AUC (Area Under the Curve) 给出的是分类器的平均性能值。

举个简单的例子，一共有5个样本，其中+表示正样本，-表示负样本，我们把5个样本按照模型A预测的score从小到大排序，得到 (-，+，-，+，+). 

根据分类阈值从大到小，我们可以得到对应横、纵轴上的点：

| TPR  | 0/3  | 1/3  | 2/3  | 2/3  | 3/3  | 3/3  |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| FPR  | 0/2  | 0/2  | 0/2  | 1/2  | 1/2  | 2/2  |

其中$TPR = \dfrac{TP}{TP+FN}= \dfrac{TP}{{\#正样本}}$,  $FPR = \dfrac{FP}{FP+TN}=\dfrac{FP}{\# 负样本}$

那么实际的AUC应该是 $(2+3)/(3*2)=0.833$

再举一个简单的例子，另一个模型B把同样的5个样本预测为(-，+，+，-，+)，可以得到类似表格：

| TPR  | 0/3  | 1/3  | 1/3  | 2/3  | 3/3  | 3/3  |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| FPR  | 0/2  | 0/2  | 1/2  | 1/2  | 1/2  | 2/2  |

可以得到AUC为$(1+3)/(3*2) = 0.67$

## GAUC

我们把上面的例子在细化一下，现在假设5个样本分别属于两个用户甲和乙。把5个样本按照模型A预测的score从小到大排序，得到乙-，甲+，甲-，甲+，乙+; 对于模型B，把这5个样本根据预测的score从小到大排序后，得到 甲-，甲+，甲+，乙-，乙+。

根据上文AUC中的分析我们知道，模型A的AUC=0.833而模型B的AUC=0.677。根据auc的表现来看，模型A的表现优于模型B。但是从实际情况来看，对于用户甲，模型B把其所有的负样本的打分都比正样本低。因此，对于用户甲，模型B的auc是1， 同理对于用户乙，模型B的auc也应该是1。所以从实际情况来看，模型B的效果要是要比模型A好的，这和实际的auc的结果矛盾。

**因此，auc这个指标在该情景下可能失真了，因为用户广告之间的排序是个性化的，不同用户的排序结果不太好比较，这可能导致全局auc并不能反映真实情况。**

auc反映的是整体样本间的一个排序能力，而在计算广告领域，我们实际要衡量的是，对于不同用户所产生的广告的排序能力。为此，阿里妈妈团队提出了评价指标group auc，即计算每个用户的auc，然后加权平均，这样能减少不同用户间的排序结果不太好比较这一影响。group AUC具体公式如下：

$$ GAUC=\dfrac{\sum_{u} w_{u} * A U C_{u}}{\sum_{u} w_{u}} $$

其中$W_u$代表用户`u`被曝光的次数=算法推荐给`u`物品的次数。

## 参考资料

- 《机器学习实战》(《Machine Learning in Action》)，非均衡分类问题

- 机器学习算法评价指标之group auc [gauc](https://blog.csdn.net/hnu2012/article/details/87892368)

- ROC曲线和AUC值 https://zhuanlan.zhihu.com/p/58587448

  